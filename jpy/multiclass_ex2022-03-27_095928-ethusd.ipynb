{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "MODEL PERFORMANCE & ANALYSIS\n",
    "- F1 Score by p-thresholds\n",
    "- Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from common.paths import Paths\n",
    "from common.utils.estimations import f1_score_weighted_returns\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ex = 'ex2022-03-27_095928-ethusd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(Paths.trade_model, ex, 'boosters.p'), 'rb') as f:\n",
    "    boosters = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'pred_label_val.p'), 'rb') as f:\n",
    "    pred_label_val = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'pred_label_ho.p'), 'rb') as f:\n",
    "    pred_label_ho = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'label_val.p'), 'rb') as f:\n",
    "    ps_label = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'label_ho.p'), 'rb') as f:\n",
    "    ps_label_ho = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'return_val.p'), 'rb') as f:\n",
    "    ps_label_return_val = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'return_ho.p'), 'rb') as f:\n",
    "    ps_label_return_ho = pickle.load( f)\n",
    "ps_label_return_val.name = 'return'\n",
    "ps_label_return_ho.name = 'return'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2check = pred_label_val\n",
    "ps_return = ps_label_return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this is a bad metric due to rounding of scores\n",
    "from sklearn.metrics import f1_score\n",
    "print('VALIDATION')\n",
    "for i, side in enumerate(['short', 'flat', 'long']):\n",
    "    print(f\"{side}: {f1_score(np.where(pred_label_val['label'] == i, 1, 0), pred_label_val[side].round().values)}\")\n",
    "print('HOLDOUT')\n",
    "for i, side in enumerate(['short', 'flat', 'long']):\n",
    "    print(f\"{side}: {f1_score(np.where(pred_label_ho['label'] == i, 1, 0), pred_label_ho[side].round().values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normed_feature_importance(boosters) -> pd.Series:\n",
    "    # sum of importances will be 1\n",
    "    from common.utils.util_func import get_model_fscore\n",
    "    importances = [get_model_fscore(booster) for booster in boosters]\n",
    "    df_imp = pd.DataFrame(importances).mean(axis=0).sort_values(ascending=False)\n",
    "    df_imp = df_imp / df_imp.sum()\n",
    "    return df_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ps_imp = normed_feature_importance(boosters)\n",
    "df_imp = pd.DataFrame(ps_imp.cumsum()).reset_index().rename(columns={'index': 'feature', 0: 'score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "  \"width\": 600,\n",
    "  \"data\": {\n",
    "    \"values\": df_imp.to_dict('records')\n",
    "  },\n",
    "  \"mark\": \"bar\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"feature\", \"type\": \"ordinal\",\n",
    "          \"sort\": \"y\"},\n",
    "      \"y\": {\"field\": \"score\", \"type\": \"quantitative\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feat_keep = df_imp[df_imp['score'] < 0.99]['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(feat_keep))\n",
    "print(feat_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2check['short'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_short = 0.30\n",
    "min_long = 0.30\n",
    "ix_pos_long = np.where((df2check['long'] > df2check['short']) & (df2check['long'] > min_long))[0]\n",
    "ix_pos_short = np.where((df2check['short'] > df2check['long']) & (df2check['short'] > min_short))[0]\n",
    "ix_pos = ix_pos_long.tolist() + ix_pos_short.tolist()\n",
    "\n",
    "#ix_neg_long = np.array(list(set(np.where(label2check > threshold)[0]).difference(ix_pos)))\n",
    "#ix_neg_short = np.array(list(set(np.where(label2check < (2-threshold))[0]).difference(ix_pos)))\n",
    "#ix_neg = np.array(ix_neg_long.tolist() + ix_neg_short.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Correlate Confidence and Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "side = 'long'\n",
    "q = 0.9\n",
    "iloc = df2check.reset_index().index[df2check[side] > df2check[side].quantile(q)]\n",
    "df = pd.concat((df2check.iloc[iloc], ps_return.iloc[iloc]), axis=1)\n",
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "  \"width\": 600,\n",
    "    \"title\": \"Short preg against return\",\n",
    "    \"description\": \"Ideally error towards zero with lower spread\",\n",
    "  \"data\": {\n",
    "    \"values\": df[[side, \"return\"]].sample(1000).to_dict('records')\n",
    "  },\n",
    "  \"mark\": {\n",
    "      \"type\": \"point\",\n",
    "    \"size\": 1,\n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": side, \"type\": \"quantitative\", \"title\": \"Preds Short\", \"scale\": {\"domain\": [df[side].min(), df[side].max()]}},\n",
    "    \"y\": {\"field\": \"return\", \"type\": \"quantitative\", \"title\": \"Return\", \"scale\": {\"domain\": [0.95, 1.05]}},\n",
    "#       \"color\": {\"field\": \"B\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ps_label_return_ho[ix_pos_long].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f1_score_weighted_returns(ix_pos_long, ix_pos_short, ix_neg, df_wide['Q-0.5'], label2check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 700,\n",
    "    \"data\": {\n",
    "        \"values\": df_long.sample(1000).to_dict('records')\n",
    "      },\n",
    "    \"mark\": {\"type\": \"line\", \"tooltip\": True},\n",
    "    \"encoding\": {\n",
    "            \"x\": {\"field\": \"index\", \"type\": \"temporal\"},\n",
    "            \"y\": {\"field\": \"value\", \"type\": \"quantitative\", \"scale\": {\"domain\": [0.985, 1.015]}},\n",
    "            \"color\": {\"field\": \"cat\"}\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for quantile in pred_label_val.keys():\n",
    "    print(f'QUANTILE: {quantile}')\n",
    "    print(f\"VALIDATION: \"\n",
    "          f\"MAE: {mean_absolute_error(pred_label_val[quantile].iloc[:, 0], pred_label_val[quantile]['label'])} \"\n",
    "          f\"MSE: {mean_squared_error(pred_label_val[quantile].iloc[:, 0], pred_label_val[quantile]['label'])}\")\n",
    "    print(f\"HOLDOUT: \"\n",
    "          f\"MAE: {mean_absolute_error(pred_label_ho[quantile].iloc[:, 0], pred_label_ho[quantile]['label'])} \"\n",
    "          f\"MSE: {mean_squared_error(pred_label_ho[quantile].iloc[:, 0], pred_label_ho[quantile]['label'])}\")\n",
    "    print(f\"RETURN == 1: \"\n",
    "          f\"MAE: {mean_absolute_error(np.ones(len(pred_label_ho[quantile])), pred_label_ho[quantile]['label'])} \"\n",
    "          f\"MSE: {mean_squared_error(np.ones(len(pred_label_ho[quantile])), pred_label_ho[quantile]['label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for quantile in pred_label_val.keys():\n",
    "    lst.append({'stage': 'VAL',\n",
    "                'quantile': quantile,\n",
    "                'MAE': mean_absolute_error(pred_label_val[quantile].iloc[:, 0], pred_label_val[quantile]['label']),\n",
    "                'MSE': mean_squared_error(pred_label_val[quantile].iloc[:, 0], pred_label_val[quantile]['label'])\n",
    "                })\n",
    "    lst.append({'stage': 'HO',\n",
    "                'quantile': quantile,\n",
    "                'MAE': mean_absolute_error(pred_label_ho[quantile].iloc[:, 0], pred_label_ho[quantile]['label']),\n",
    "                'MSE': mean_squared_error(pred_label_ho[quantile].iloc[:, 0], pred_label_ho[quantile]['label'])\n",
    "                })\n",
    "    lst.append({'stage': 'HO - BASELINE PRED=1',\n",
    "                'quantile': quantile,\n",
    "                'MAE': mean_absolute_error(np.ones(len(pred_label_ho[quantile])), pred_label_ho[quantile]['label']),\n",
    "                'MSE': mean_squared_error(np.ones(len(pred_label_ho[quantile])), pred_label_ho[quantile]['label'])\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "  \"data\": {\n",
    "    \"values\": lst\n",
    "  },\n",
    "  \"mark\": \"line\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"quantile\", \"type\": \"ordinal\"},\n",
    "    \"y\": {\"field\": \"MAE\", \"type\": \"quantitative\"},\n",
    "      \"color\": {\"field\": \"stage\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION ERRORS by confidence. Smaller confidence, lower error ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df[[0]] for df in pred_label_ho.values()] + [pred_label_ho[0.1][\"label\"]], axis=1)\n",
    "df.columns=list(pred_label_ho.keys()) + ['label']\n",
    "df['confidence_spread'] = df[0.9] - df[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"title\": \"Confidence Spread over time\",\n",
    "  \"width\": 600,\n",
    "  \"data\": {\n",
    "    \"values\": df.reset_index()[['index', 'confidence_spread']].sample(1000).to_dict('records')\n",
    "  },\n",
    "  \"mark\": \"line\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"index\", \"type\": \"temporal\"},\n",
    "    \"y\": {\"field\": \"confidence_spread\", \"type\": \"quantitative\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mid'] = df['0.5']\n",
    "df['low'] = df['0.1']\n",
    "df['up'] = df['0.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_mae = {}\n",
    "quantiles = list(range(1, 10))\n",
    "for quantile in quantiles:\n",
    "    threshold_high = df['0.5'].quantile(quantile/10)\n",
    "    threshold_low = df['0.5'].quantile((quantile-1)/10)\n",
    "    ix = np.where((df['0.5'] > threshold_low) & (df['0.5'] < threshold_high))[0]\n",
    "    quantile_mae[round(threshold_high - (threshold_high - threshold_low)/2, 3)] = mean_absolute_error(df.iloc[ix]['0.5'], df.iloc[ix]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this one want to have count sample as well\n",
    "# instead \n",
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "    \"title\": \"Quantile of Predicted return\",\n",
    "    \"description\": \"Ideally error towards zero with lower spread\",\n",
    "  \"data\": {\n",
    "    \"values\": [{'quantile': k, 'Loss': v} for k, v in quantile_mae.items()]\n",
    "  },\n",
    "  \"mark\": \"line\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"quantile\", \"type\": \"ordinal\", \"title\": \"Quantile of Predicted return\"},\n",
    "    \"y\": {\"field\": \"Loss\", \"type\": \"quantitative\", \"title\": \"MAE\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_mae = {}\n",
    "quantiles = list(range(1, 10))\n",
    "for quantile in quantiles:\n",
    "    threshold_high = df['confidence_spread'].quantile(quantile/10)\n",
    "    threshold_low = df['confidence_spread'].quantile((quantile-1)/10)\n",
    "    ix = np.where((df['confidence_spread'] > threshold_low) & (df['confidence_spread'] < threshold_high))[0]\n",
    "    quantile_mae[quantile] = mean_absolute_error(df.iloc[ix]['0.5'], df.iloc[ix]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [str(c) for c in df.columns]\n",
    "df[\"Loss\"] = df[\"0.5\"] - df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "    \"title\": \"Regression error against confidence spread of 0.1 and 0.9 line\",\n",
    "    \"description\": \"Ideally error towards zero with lower spread\",\n",
    "  \"data\": {\n",
    "    \"values\": df[[\"Loss\", \"confidence_spread\"]].sample(1000).to_dict('records')\n",
    "  },\n",
    "  \"mark\": {\n",
    "      \"type\": \"point\",\n",
    "    \"size\": 1,  \n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"confidence_spread\", \"type\": \"quantitative\", \"title\": \"Confidence spread\"},\n",
    "    \"y\": {\"field\": \"Loss\", \"type\": \"quantitative\", \"title\": \"0.5 Regression Error\"\n",
    "#           \"scale\": {\"domain\": [0.95, 1]}\n",
    "         },\n",
    "#       \"color\": {\"field\": \"B\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "   \"title\": \"Tranches of Confidence Spread against 0.5 MAE Loss.\",\n",
    "    \"description\": \"Ideally -x**2 mirror parabolic\",\n",
    "  \"data\": {\n",
    "    \"values\": [{'quantile': k, 'Loss': v} for k, v in quantile_mae.items()]\n",
    "  },\n",
    "  \"mark\": \"line\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"quantile\", \"type\": \"ordinal\", \"title\": \"Quantile of regression confidence spread\"},\n",
    "    \"y\": {\"field\": \"Loss\", \"type\": \"quantitative\", \"title\": \"Loss of 0.5 qt regression model\"\n",
    "#           \"scale\": {\"domain\": [0.95, 1]}\n",
    "         },\n",
    "#       \"color\": {\"field\": \"stage\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the error correlate significant high return events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "    \"title\": \"Future Return against Regression Error. Ideally a horizontal line thinning out on ends.\",\n",
    "  \"data\": {\n",
    "    \"values\": df[[\"Loss\", \"label\"]].sample(1000).to_dict('records')\n",
    "  },\n",
    "  \"mark\": {\n",
    "      \"type\": \"point\", \n",
    "      \"size\": 1,  \n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"label\", \"type\": \"quantitative\", \"title\": \"Future Return\", \"scale\": {\"domain\": [0.95, 1.05]}},\n",
    "    \"y\": {\"field\": \"Loss\", \"type\": \"quantitative\", \"title\": \"0.5 Regression Error\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "    \"title\": \"Future Return against Predicted. Should ideally be a circle...\",\n",
    "  \"data\": {\n",
    "    \"values\": df[[\"mid\", \"label\"]].sample(1000).to_dict('records')\n",
    "  },\n",
    "  \"mark\": {\n",
    "      \"type\": \"point\", \n",
    "      \"size\": 1,  \n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"label\", \"type\": \"quantitative\", \"title\": \"Future Return\", \"scale\": {\"domain\": [0.95, 1.05]}},\n",
    "    \"y\": {\"field\": \"mid\", \"type\": \"quantitative\", \"title\": \"Predicted\", \"scale\": {\"domain\": [0.95, 1.05]}},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart.from_dict({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.json\",\n",
    "  \"width\": 600,\n",
    "    \"title\": \"Future Return against Confidence Range. Best if a reverse parabola\",\n",
    "  \"data\": {\n",
    "    \"values\": df[[\"confidence_spread\", \"label\"]].sample(1000).to_dict('records')\n",
    "  },\n",
    "  \"mark\": {\n",
    "      \"type\": \"point\", \n",
    "      \"size\": 1,  \n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"label\", \"type\": \"quantitative\", \"title\": \"Future Return\", \"scale\": {\"domain\": [0.95, 1.05]}},\n",
    "    \"y\": {\"field\": \"confidence_spread\", \"type\": \"quantitative\", \"title\": \"confidence_spread\"},\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More questions. Hypothesis. P values. confidence intervals such as:\n",
    "Given a predicted return increase of [x1,.. xn], how likely is that the return goes over [y1, .. yn]\n",
    "Basically, is anything better than guess, at least marginally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini Backtest**\n",
    "- Entry:\n",
    "    - Predicted return </> thresholds\n",
    "    - Confidence spread < its mean\n",
    "- Exit conditions:\n",
    "    - Trailing Stop Loss\n",
    "    - Timeout\n",
    "    - Predictions suggest reversal\n",
    "    - Maybe profit taking ...\n",
    "Plot Graph 2 images. Prices and PnL Series. Each couple layers (buy sell points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from common.utils.util_func import get_model_fscore\n",
    "# importances = [get_model_fscore(booster) for booster in self.boosters]\n",
    "# res = pd.DataFrame(importances).mean(axis=0).sort_values(ascending=False)\n",
    "# logger.info(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from common.utils.util_func import get_model_fscore\n",
    "\n",
    "importances = [get_model_fscore(booster) for booster in boosters]\n",
    "res = pd.DataFrame(importances).mean(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(res.iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "VALIDATION F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(Paths.trade_model, ex, 'preds.p'), 'rb') as f:\n",
    "    preds = pickle.load(f)\n",
    "with open(os.path.join(Paths.trade_model, ex, 'label.p'), 'rb') as f:\n",
    "    label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f1 = preds.merge(label, how='inner', right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "HOLDOUT SET VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from layers.predictions.predict import Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2022, 2, 17)\n",
    "end = datetime.datetime(2022, 3, 1)\n",
    "f1_ho = Predict(boosters, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(Paths.trade_model, ex, 'f1_ho.p'), 'rb') as f:\n",
    "#     f1_ho = pickle.load(f)\n",
    "for i, side in enumerate(['short', 'flat', 'long']):\n",
    "    print(f\"{side}: {f1_score(np.where(f1_ho['label'] == i, 1, 0), f1_ho[side].round().values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
