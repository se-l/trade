{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from common.modules.enums import Exchange, Direction\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from connector.influxdb.influxdb_wrapper import influx\n",
    "\n",
    "path_ex = Path(os.getcwd()).parent.parent.joinpath('experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For any series of events (bars) beyond exceeding expectations, eg., vector of ts/sum of runs -\n",
    "are returns exceeding expections ?\n",
    "Vector events x Mat(return products x ts) => another Mat. what's that inner product exactly?\n",
    "    what's a signficantly different return?\n",
    "H0: p(r > 1 | signficant imbalance) == 0.5\n",
    "H0: p(r < 1 | signficant imbalance) == 0.5\n",
    "H1  p(r > 1 | significant imbalance) > 0.5\n",
    "\n",
    "r needs to be stationary for these tests, such as that E0(mean(r)) == Product(r) == 1. Given an imbalance like that shock, expect product(r) to deviate how much?\n",
    "\n",
    "1. bars likely not stationary. Make stationary or just use EWM to search for outliers.\n",
    "2. Get vector of outliers. Time / amplitude\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alpha: Signifacant one-sided volume imbalance without significant price change -> Order Book holds. Precedes price move\n",
    "Data needed: rolling return, rolling trade volume imbalance.\n",
    "Feature: rolling volume imbalance per unit of return. if large, means much volum no price change indicative of reversal\n",
    "\n",
    "need accessory: order book imbalance (ewm across levels, low levels more important than higher levels) - start pulling exchange data in realtime and append to text file split by exchange, symbol, trade/quote, day. Soonish have enough to model with it ~ 1week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_ex = 'ex 2022-02-02 190202'\n",
    "start = datetime.datetime(2020, 1, 1)\n",
    "end = datetime.datetime(2020, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(path_ex, p_ex, 'lala.json'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- if not stationary, use fractional differentiation to turn it into 1\n",
    "- get special events, 1 sigma away, 2 sigma away from mean... is not gaussian - so just select outliers... top 5%. get all above expected value ??? min/low 5 % may not be outliers...\n",
    "-       rather... what;s the expecation? EWM ...\n",
    "- for each special event analyse state and profit\n",
    "    state eventually defined by hundreds of stationary series with thousands of events per year\n",
    "    that's where ML starts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = influx.query(query=f'''\n",
    "            from(bucket:\"trading\")\n",
    "            |> range(start: {start.isoformat()}Z, stop: {end.isoformat()}Z)\n",
    "            |> filter(fn:(r) => r._measurement == \"trade bars\" and\n",
    "                                r.asset == \"ethusd\" and\n",
    "                                r._field == \"imbalance_size\" and\n",
    "                                r.information == \"imbalance_per_plus_tick\"\n",
    "                     )\n",
    "            '''\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_stationary(arr: np.array):\n",
    "    \"\"\"\n",
    "    Augmented Dickey-Fuller test\n",
    "    https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "    p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "    \"\"\"\n",
    "    result = adfuller(df['imbalance_size'].values)\n",
    "    print(f'''p-value: {result[1]} - ADF Statistic: {result[0]}''')\n",
    "    # for key, value in result[4].items():\n",
    "    #     print('\\t%s: %.3f' % (key, value))\n",
    "    return result[1] <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not is_stationary(df.values):\n",
    "    print('Fractional differencing on series')\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "low = df['imbalance_size'].quantile(q=0.025)\n",
    "high = df['imbalance_size'].quantile(q=1-0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['imbalance_size'].sort_values()[99 * len(df)// 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['imbalance_size'].sort_values()[1 * len(df)// 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
